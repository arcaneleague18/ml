import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
#from sklearn.linear_model import LogisticRegression #for logistic regression
# from sklearn.neighbors import KNeighborsClassifier #for KNN algorithm
from sklearn.tree import DecisionTreeClassifier # for decision tree
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score, recall_score, precision_score

df = pd.DataFrame([
    [5.1, 3.5, 1.4, 0.2, "Iris-setosa"],
    [4.9, 3.0, 1.4, 0.2, "Iris-setosa"],
    [5.8, 2.7, 4.1, 1.0, "Iris-versicolor"],
    [6.0, 2.2, 4.0, 1.2, "Iris-versicolor"],
    [6.9, 3.1, 4.9, 1.5, "Iris-versicolor"],
    [6.5, 3.0, 5.8, 2.2, "Iris-virginica"],
    [7.6, 3.0, 6.6, 2.1, "Iris-virginica"],
    [4.6, 3.1, 1.5, 0.2, "Iris-setosa"],
    [6.7, 3.3, 5.7, 2.5, "Iris-virginica"],
    [5.5, 2.3, 4.0, 1.3, "Iris-versicolor"],
], columns = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', "Species"])

X = df.drop("Species", axis=1) 
y = df['Species']  # replace with the target column name

X_train, X_test, y_train, y_test = train_test_split(X, y)

# classifier = LogisticRegression() 
#classifier = KNeighborsClassifier(n_neighbors = 3)
classifier = DecisionTreeClassifier(criterion='entropy', max_depth=3)
classifier.fit(X_train, y_train)

print(classifier)

y_pred = classifier.predict(X_test)
print([X_test, y_test])
print(y_pred)


cm = confusion_matrix(y_test, y_pred)
# precision = precision_score(y_test, y_pred)
# recall = recall_score(y_test, y_pred)
accuracy = accuracy_score(y_test, y_pred)


# for binary classification, ensure that there are only two unique classes in the target variable, the rest of the code remains same

print(cm)
print(accuracy)

